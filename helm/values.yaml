# Default values for mediawiki.
# This is a YAML-formatted file.
# Declare variables to be passed into the templates.

global:
  nameOverride: ""
  fullnameOverride: ""
  licenseplate: "abcdef"
  cluster: "silver"
  serviceAccount:
    name: "abcdef-vault"
    # Specifies whether a service account should be created
    create: false
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
  # Inject Keycloak JSON multi-value config from a Vault secret
  # See details: https://digital.gov.bc.ca/technology/cloud/private/products-tools/vault/
  vault:
    # Vault role for this service
    role: "abcdef-nonprod" 
    # Secrets path in container
    secret: "secrets-name"
    # Vault engine to use
    engine: "nonprod"

mediawiki:

  replicaCount: 1

  image:
    repository: ghcr.io/bcgov/isd-wiki
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"

  imagePullSecrets: []
  nameOverride: ""
  fullnameOverride: ""

# These values would come from the Dockerfile's ENV variables
  # or from the official MediaWiki Docker image documentation.
  # For now, let's assume direct configuration.
  # the'll likely map these to environment variables in the deployment.yaml
  database:
    type: postgresql
    host: "patroni-isd-wiki"
    port: 5432
    name: mediawiki
    user: mediawiki
    password: ""
    rootPassword: ""

  # Configuration for LocalSettings.php
  siteName: "My MediaWiki"
  adminUser: "admin"
  adminPassword: "" # Set this securely
  # Add more MediaWiki-specific settings here, which the can inject into LocalSettings.php


  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podLabels: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If the do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

crunchy-postgres:
  fullnameOverride: crunchy-postgres

  crunchyImage: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
  #crunchyImage: artifacts.developer.gov.bc.ca/bcgov-docker-local/crunchy-postgres-gis:ubi8-15.2-3.3-0 # use this image for POSTGIS
  postgresVersion: 15
  #postGISVersion: '3.3' # use this version of POSTGIS.
  imagePullPolicy: IfNotPresent
  #openshift, so it stops putting invalid security context constraints on the pods
  openshift: true

  # enable to bootstrap a standby cluster from backup. Then disable to promote this standby to primary
  standby:
    enabled: false
    # If you want to recover from PVC, use repo1. If you want to recover from S3, use repo2
    repoName: repo2

  instances:
    name: ha # high availability
    replicas: 2
    dataVolumeClaimSpec:
      storage: 480Mi
      storageClassName: netapp-block-standard
    requests:
      cpu: 1m
      memory: 256Mi
    replicaCertCopy:
      requests:
        cpu: 1m
        memory: 32Mi

  # If we need to restore the cluster from a backup, we need to set the following values
  # assuming restore from repo2 (s3), adjust as needed if your S3 repo is different
  dataSource:
    enabled: false
    # should have the same name and contain the same keys as the pgbackrest secret
    secretName: s3-pgbackrest
    repo:
      name: repo2
      path: "/habackup"
      s3:
        bucket: "bucketName"
        endpoint: "s3.ca-central-1.amazonaws.com"
        region: "ca-central-1"
      stanza: db

  pgBackRest:
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    retention: "2" # Ideally a larger number such as 30 backups/days
    # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
    # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
    retentionFullType: count
    repos:
      schedules:
        full: 0 8 * * *
        incremental: 0 0,4,12,16,20 * * *
      volume:
        accessModes: "ReadWriteOnce"
        storage: 64Mi
        storageClassName: netapp-file-backup
    repoHost:
      requests:
        cpu: 1m
        memory: 64Mi
    sidecars:
      requests:
        cpu: 1m
        memory: 64Mi
    s3:
      enabled: false
      createS3Secret: true
      # the s3 secret name
      s3Secret: s3-pgbackrest
      # the path start with /, it will be created under bucket if it doesn't exist
      s3Path: "/habackup"
      # s3UriStyle is host or path
      s3UriStyle: path
      # bucket specifies the S3 bucket to use,
      bucket: "bucketName"
      # endpoint specifies the S3 endpoint to use.
      endpoint: "endpointName"
      # region specifies the S3 region to use. If your S3 storage system does not
      # use "region", fill this in with a random value.
      region: "ca-central-1"
      # key is the S3 key. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      key: "s3keyValue"
      # keySecret is the S3 key secret. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      keySecret: "s3SecretValue"
      # setting the below to be one plus of the default schedule
      # to avoid conflicts
      fullSchedule: "0 9 * * *"
      incrementalSchedule: "0 1,5,13,17,21 * * *"

  patroni:
    postgresql:
      pg_hba: "host all all 0.0.0.0/0 md5"
      parameters:
        shared_buffers: 16MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
        wal_buffers: "64kB" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
        min_wal_size: 32MB
        max_wal_size: 64MB # default is 1GB
        max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind

  proxy:
    pgBouncer:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      replicas: 2
      requests:
        cpu: 1m
        memory: 64Mi

  # Postgres Cluster resource values:
  pgmonitor:
    enabled: false
    exporter:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      requests:
        cpu: 1m
        memory: 64Mi



crunchy-postgres-tools:

  fullnameOverride: crunchy-postgres-tools
  deploymentName: crunchy-postgres

  deployer:
    serviceAccount:
      enabled: true

  # Enable the provisioner service account which is used to deploy services to our other namespaces (dev/test/prod)
  # The tools namespace needs to be passed in so we know which namespace to install the service account in and the rolebindings get proper permissions
  provisioner:
    namespace: #tools-namespace
    serviceAccount:
      enabled: true

  # Service account with fairly low permissions for the linter
  linter:
    serviceAccount:
      enabled: true

  networking:
    # Network policy to allow traffic from outside the namespace (like the internet)
    networkPolicy:
      enabled: true
    # Pod network policy to allow pods to accept traffic from other pods in this namespace
    podNetworkPolicy:
      enabled: true
    # Enable OpenShift route whitch allows you to host your application at a public URL
    route:
      enabled: false
      host: # eg: crunchy-postgres-namespace.apps.silver.devops.gov.bc.ca
      
# patroni:

#   # # Default values for patroni.
#   # # This is a YAML-formatted file.
#   # # Declare variables to be passed into your templates.

#   # replicaCount: 1

#   # image:
#   #   repository: artifacts.developer.gov.bc.ca/bcgov-docker-local
#   #   pullPolicy: Always
#   #   # Overrides the image name whose default is the chart name.
#   #   name: patroni-postgres
#   #   # Overrides the image tag whose default is the chart appVersion.
#   #   tag: ~

#   # imagePullSecrets: []
#   # nameOverride: ~
#   # fullnameOverride: ~

#   # credentials:
#   #   # # Username of replication account
#   #   # replicationUsername: replication
#   #   # # Username of superuser account
#   #   # superuserUsername: postgres
#   #   # Application database name
#   #   appDbName: mediawiki
#   #   # Username of application account
#   #   appDbUserame: mediawiki
#   # # To use an existing secret instead of having the chart generate one, provide the name of the existing secret here.
#   # # Note that this secret must be formatted the same way as the secret generated by the chart.
#   # # Leave it blank to allow the helm chart to generate a secret for you.
#   # secretOverride: ~

#   # serviceAccount:
#   #   # Specifies whether a service account should be created
#   #   create: true
#   #   # Annotations to add to the service account
#   #   annotations: {}
#   #   # The name of the service account to use.
#   #   # If not set and create is true, a name is generated using the fullname template
#   #   name: ~

#   # podAnnotations: {}

#   # podAntiAffinity: true

#   # podSecurityContext: {}
#   #   # fsGroup: 2000

#   # securityContext: {}
#   #   # capabilities:
#   #   #   drop:
#   #   #   - ALL
#   #   # readOnlyRootFilesystem: true
#   #   # runAsNonRoot: true
#   #   # runAsUser: 1000

#   # service:
#   #   enableReadOnly: true
#   #   # Annotations to add to the service account
#   #   annotations: {}
#   #   type: ClusterIP
#   #   port: 5432
#   #   portName: db

#   # networkPolicy:
#   #   enabled: true

#   # probes:
#   #   liveness:
#   #     enabled: true
#   #   readiness:
#   #     enabled: true

#   # resources:
#   #   # We usually recommend not to specify default resources and to leave this as a conscious
#   #   # choice for the user. This also increases chances charts run on environments with little
#   #   # resources, such as Minikube. If you do want to specify resources, uncomment the following
#   #   # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
#   #   limits:
#   #     cpu: 500m
#   #     memory: 512Mi
#   #   requests:
#   #     cpu: 20m
#   #     memory: 256Mi

#   # persistentVolume:
#   #   enabled: true
#   #   accessModes:
#   #     - ReadWriteOnce
#   #   annotations: {}
#   #   mountPath: "/home/postgres/pgdata"
#   #   size: 2Gi
#   #   storageClass: "netapp-block-standard"


#   replicaCount: 3

#   image:
#     # see https://github.com/zalando/spilo/releases
#     repository: ghcr.io/zalando/spilo-15
#     pullPolicy: Always
#     tag: 3.2-p1

#   imagePullSecrets: []
#   nameOverride: ""
#   fullnameOverride: ""

#   postgresMajorVersion: 15

#   # Credentials used by Patroni
#   credentials:
#     existingSecret: false
#     superuser:
#       username: postgres
#       password:
#     admin:
#       username: admin
#       password:
#     standby:
#       username: standby
#       password:

#   # Additional users and databases; each user will have full privileges on the same name of the database
#   # leave the password empty to generate the password automatically
#   # example
#   # additionalCredentials:
#   #   - username: myapp
#   #     password:
#   additionalCredentials: []

#   # set to allow clients to connect without SSL enabled.
#   allowNoSSL: true

#   # Distribution Configuration stores
#   # Please note that only one of the following stores should be enabled.
#   kubernetes:
#     roleLabel: "spilo-role"
#     dcs:
#       enable: true
#     configmaps:
#       enable: true

#   etcd:
#     enable: false
#     deployChart: false
#     # If not deploying etcd chart, fill-in value for etcd service
#     # <service>.<namespace>.svc.cluster.local
#     host:
#     # Leave blank to use vendored etcd chart
#     discovery:
#   zookeeper:
#     enable: false
#     deployChart: false
#     # If not deploying etcd chart, fill-in list of ZooKeeper members in format:
#     # 'host1:port1','host2:port2','etc...'
#     hosts:
#   consul:
#     enable: false
#     deployChart: false
#     # Leave blank to use vendored consul chart
#     hosts:

#   # Extra custom environment variables.
#   # see https://github.com/zalando/spilo/blob/master/ENVIRONMENT.rst#environment-configuration-settings
#   env: {}

#   walG:
#     # Specifies whether Wal-G should be enabled
#     enabled: false
#     # Cron schedule for doing base backups
#     scheduleCronJob: 00 01 * * *
#     # Amount of base backups to retain
#     retainBackups: 2
#     # Maximum size of the WAL segments accumulated after the base backup to
#     # consider WAL-G restore instead of pg_basebackup
#     backupThresholdMegabytes: 1024
#     # Maximum ratio (in percents) of the accumulated WAL files to the base backup
#     # to consider WAL-G restore instead of pg_basebackup
#     backupThresholdPercentage: 30

#     # see https://github.com/wal-g/wal-g/blob/master/docs/STORAGES.md
#     storage: pvc
#     pvc:
#       size: 500Mi
#       storageClass: netapp-file-backup
#       mountPath: /home/postgres/backups

#   rbac:
#     # Specifies whether RBAC resources should be created
#     create: true

#   serviceAccount:
#     # Specifies whether a service account should be created
#     create: true
#     # Annotations to add to the service account
#     annotations: {}
#     # The name of the service account to use.
#     # If not set and create is true, a name is generated using the fullname template
#     name: ""

#   persistentVolume:
#     enabled: true
#     size: 1G
#     storageClass: netapp-block-standard
#     subPath: ""
#     mountPath: /home/postgres/pgdata
#     annotations: {}
#     accessModes:
#       - ReadWriteOnce

#   resources:
#     {}
#     # We usually recommend not to specify default resources and to leave this as a conscious
#     # choice for the user. This also increases chances charts run on environments with little
#     # resources, such as Minikube. If you do want to specify resources, uncomment the following
#     # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
#     # limits:
#     #   cpu: 100m
#     #   memory: 128Mi
#     # requests:
#     #   cpu: 100m
#     #   memory: 128Mi

#   # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
#   nodeSelector: {}

#   # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
#   tolerations: []

#   # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
#   affinityTemplate: |
#     podAntiAffinity:
#       preferredDuringSchedulingIgnoredDuringExecution:
#       - weight: 100
#         podAffinityTerm:
#           topologyKey: "kubernetes.io/hostname"
#           labelSelector:
#             matchLabels: {{ include "patroni.selectorLabels" . | nindent 10 }}

#   affinity: {}
#   ## Use an alternate scheduler, e.g. "stork".
#   ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
#   ##
#   # schedulerName:

#   networkPolicy:
#     enabled: true

#   podDisruptionBudget:
#     enabled: true
#     minAvailable: 1
#     maxUnavailable:

#   standby:
#     enabled: false
#     host:
#     port: 5433

#   transportServerClaim:
#     enabled: false
#     interval: 10
#     timeout: 10
