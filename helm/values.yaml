# Default values for mediawiki.
# This is a YAML-formatted file.
# Declare variables to be passed into the templates.

global:
  nameOverride: ""
  fullnameOverride: ""
  licenseplate: "abcdef"
  cluster: "silver"
  serviceAccount:
    name: "abcdef-vault"
    # Specifies whether a service account should be created
    create: false
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
  # Inject Keycloak JSON multi-value config from a Vault secret
  # See details: https://digital.gov.bc.ca/technology/cloud/private/products-tools/vault/
  vault:
    # Vault role for this service
    role: "abcdef-nonprod" 
    # Secrets path in container
    secret: "secrets-name"
    # Vault engine to use
    engine: "nonprod"

mediawiki:

  replicaCount: 1

  image:
    repository: ghcr.io/bcgov/isd-wiki
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"

  imagePullSecrets: []
  nameOverride: ""
  fullnameOverride: ""

# These values would come from the Dockerfile's ENV variables
  # or from the official MediaWiki Docker image documentation.
  # For now, let's assume direct configuration.
  # the'll likely map these to environment variables in the deployment.yaml
  database:
    type: postgresql
    host: "isd-wiki-db-svc"
    port: 5432
    name: mediawiki
    user: mediawiki
    password: ""
    rootPassword: ""

  # Configuration for LocalSettings.php
  siteName: "My MediaWiki"
  adminUser: "admin"
  adminPassword: "" # Set this securely
  # Add more MediaWiki-specific settings here, which the can inject into LocalSettings.php


  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podLabels: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If the do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

crunchy-postgres:

  # The name of the Crunchy Postgres instance
  fullnameOverride: isd-wiki-db

  crunchyImage: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
  #crunchyImage: artifacts.developer.gov.bc.ca/bcgov-docker-local/crunchy-postgres-gis:ubi8-15.2-3.3-0 # use this image for POSTGIS
  postgresVersion: 15
  #postGISVersion: '3.3' # use this version of POSTGIS.
  imagePullPolicy: IfNotPresent
  #openshift, so it stops putting invalid security context constraints on the pods
  openshift: true

  # enable to bootstrap a standby cluster from backup. Then disable to promote this standby to primary
  standby:
    enabled: false
    # If you want to recover from PVC, use repo1. If you want to recover from S3, use repo2
    repoName: repo2

  instances:
    name: ha # high availability
    replicas: 2
    dataVolumeClaimSpec:
      storage: 480Mi
      storageClassName: netapp-block-standard
    requests:
      cpu: 1m
      memory: 256Mi
    replicaCertCopy:
      requests:
        cpu: 1m
        memory: 32Mi

  # If we need to restore the cluster from a backup, we need to set the following values
  # assuming restore from repo2 (s3), adjust as needed if your S3 repo is different
  dataSource:
    enabled: false
    # should have the same name and contain the same keys as the pgbackrest secret
    secretName: s3-pgbackrest
    repo:
      name: repo2
      path: "/habackup"
      s3:
        bucket: "bucketName"
        endpoint: "s3.ca-central-1.amazonaws.com"
        region: "ca-central-1"
      stanza: db

  pgBackRest:
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    retention: "2" # Ideally a larger number such as 30 backups/days
    # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
    # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
    retentionFullType: count
    repos:
      schedules:
        full: 0 8 * * *
        incremental: 0 0,4,12,16,20 * * *
      volume:
        accessModes: "ReadWriteOnce"
        storage: 64Mi
        storageClassName: netapp-file-backup
    repoHost:
      requests:
        cpu: 1m
        memory: 64Mi
    sidecars:
      requests:
        cpu: 1m
        memory: 64Mi
    s3:
      enabled: false
      createS3Secret: true
      # the s3 secret name
      s3Secret: s3-pgbackrest
      # the path start with /, it will be created under bucket if it doesn't exist
      s3Path: "/habackup"
      # s3UriStyle is host or path
      s3UriStyle: path
      # bucket specifies the S3 bucket to use,
      bucket: "bucketName"
      # endpoint specifies the S3 endpoint to use.
      endpoint: "endpointName"
      # region specifies the S3 region to use. If your S3 storage system does not
      # use "region", fill this in with a random value.
      region: "ca-central-1"
      # key is the S3 key. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      key: "s3keyValue"
      # keySecret is the S3 key secret. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      keySecret: "s3SecretValue"
      # setting the below to be one plus of the default schedule
      # to avoid conflicts
      fullSchedule: "0 9 * * *"
      incrementalSchedule: "0 1,5,13,17,21 * * *"

  patroni:
    postgresql:
      pg_hba: "host all all 0.0.0.0/0 md5"
      parameters:
        shared_buffers: 16MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
        wal_buffers: "64kB" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
        min_wal_size: 32MB
        max_wal_size: 64MB # default is 1GB
        max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind

  proxy:
    pgBouncer:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      replicas: 2
      requests:
        cpu: 1m
        memory: 64Mi

  # Postgres Cluster resource values:
  pgmonitor:
    enabled: false
    exporter:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      requests:
        cpu: 1m
        memory: 64Mi